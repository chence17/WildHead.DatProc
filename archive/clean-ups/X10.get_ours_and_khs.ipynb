{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 264441/264441 [00:00<00:00, 1210635.98it/s]\n"
     ]
    }
   ],
   "source": [
    "import json, os, tqdm\n",
    "\n",
    "dataset_json_path = '/data2/chence/PanoHeadData/single_view_hq/dataset_v2.json'\n",
    "khs_train_paths = {}\n",
    "khs_val_paths = {}\n",
    "ours_paths = {}\n",
    "with open(dataset_json_path, 'r') as f:\n",
    "    dataset = json.load(f)\n",
    "\n",
    "not_shown_ours = True\n",
    "not_shown_khs = True\n",
    "for image_name, image_meta in tqdm.tqdm(dataset.items()):\n",
    "    source = image_meta['data_source']\n",
    "    if source == 'OCD/Original':\n",
    "        ours_paths[image_name] = image_meta['align_image_path']\n",
    "    elif source == 'K-Hairstyle/Validation':\n",
    "        new_path = image_meta['align_image_path'].replace('align_images', 'validation_labels')\n",
    "        if new_path.endswith('._00.png'): \n",
    "            new_path = new_path.replace('._00.png', '.json')\n",
    "        else:\n",
    "            new_path = new_path.replace('_00.png', '.json')\n",
    "        new_path = new_path.replace('-', '_')\n",
    "        khs_val_paths[image_name] = new_path\n",
    "    elif source == 'K-Hairstyle/Training':\n",
    "        new_path = image_meta['align_image_path'].replace('align_images', 'training_labels')\n",
    "        if new_path.endswith('._00.png'): \n",
    "            new_path = new_path.replace('._00.png', '.json')\n",
    "        else:\n",
    "            new_path = new_path.replace('_00.png', '.json')\n",
    "        new_path = new_path.replace('-', '_')\n",
    "        khs_train_paths[image_name] = new_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3324/3324 [00:01<00:00, 3057.53it/s]\n",
      "100%|██████████| 29907/29907 [00:10<00:00, 2845.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of attributes: 5\n",
      "Attribute 단발: Numbers 10802\n",
      "Attribute 남자: Numbers 15732\n",
      "Attribute 중발: Numbers 3002\n",
      "Attribute 장발: Numbers 1327\n",
      "Attribute 여숏: Numbers 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vis_num = 10\n",
    "label_root_dir = '/data3/khs_labels/'\n",
    "attr_name = 'length'\n",
    "\n",
    "attrs = set()\n",
    "attr_samples = {}\n",
    "\n",
    "for k, v in tqdm.tqdm(khs_val_paths.items()):\n",
    "    abs_path = os.path.join(label_root_dir, v)\n",
    "    with open(abs_path, 'r') as f:\n",
    "        label = json.load(f)\n",
    "        attr = label[attr_name]\n",
    "        attrs.add(attr)\n",
    "        if attr not in attr_samples:\n",
    "            attr_samples[attr] = [k]\n",
    "        else:\n",
    "            attr_samples[attr].append(k)\n",
    "for k, v in tqdm.tqdm(khs_train_paths.items()):\n",
    "    abs_path = os.path.join(label_root_dir, v)\n",
    "    with open(abs_path, 'r') as f:\n",
    "        label = json.load(f)\n",
    "        attr = label[attr_name]\n",
    "        attrs.add(attr)\n",
    "        if attr not in attr_samples:\n",
    "            attr_samples[attr] = [k]\n",
    "        else:\n",
    "            attr_samples[attr].append(k)\n",
    "print(f'Number of attributes: {len(attr_samples)}')\n",
    "for attr_cat, attr_val in attr_samples.items():\n",
    "    print(f'Attribute {attr_cat}: Numbers {len(attr_val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264441\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 264441/264441 [00:00<00:00, 910239.50it/s]\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "selected_dataset = 'Web'\n",
    "selected_view = 'back'\n",
    "back_view_num = 0\n",
    "vis_samples = 40\n",
    "image_root_dir = '/data2/chence/PanoHeadData/single_view_hq/align_images'\n",
    "views = {'back':0, 'front':0, 'left':0, 'right':0}\n",
    "for image_name, image_meta in tqdm.tqdm(dataset.items()):\n",
    "    source = image_meta['data_source']\n",
    "    view = image_meta['view']\n",
    "    if not(source.startswith(selected_dataset) and view == selected_view):\n",
    "        dataset[image_name]['dup_num'] = 1\n",
    "    else:\n",
    "        dataset[image_name]['dup_num'] = 10\n",
    "with open(dataset_json_path, 'w') as f:\n",
    "    json.dump(dataset, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some basestyles given that exceptional is 해당없음\n",
    "from IPython.display import display\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "image_root_dir = '/data2/chence/PanoHeadData/single_view_hq/align_images'\n",
    "num_vis = 20\n",
    "for k, v in attr_samples.items():\n",
    "    print(f'Samples of {k}')\n",
    "    vised = 0\n",
    "    fig, axs = plt.subplots(5, 4, figsize=(16, 12))\n",
    "    axs = axs.flatten()\n",
    "    for _v in attr_samples[k][::50]:\n",
    "        image_path = os.path.join(image_root_dir, _v.replace('png', 'jpg'))\n",
    "        image = Image.open(image_path)\n",
    "        print(f'{vised}: {image_path}')\n",
    "        axs[vised].imshow(image)\n",
    "        axs[vised].axis('off')\n",
    "        vised += 1\n",
    "        if num_vis == vised: \n",
    "            plt.show()\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "image_root_dir = '/data2/chence/PanoHeadData/single_view_hq/align_images'\n",
    "for k, v in hairstyle_samples.items():\n",
    "    v = v.replace('png', 'jpg')\n",
    "    image_path = os.path.join(image_root_dir, v)\n",
    "    image = Image.open(image_path)\n",
    "    print(k)\n",
    "    # specify height and width of figure in pixels\n",
    "    plt.figure(figsize=(2,2))\n",
    "    plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "해당없음\n",
      "묶음머리\n",
      "넘긴머리\n",
      "악성곱슬머리\n",
      "땋은머리\n",
      "기타악세사리\n",
      "군인머리(반삭)\n",
      "기타\n"
     ]
    }
   ],
   "source": [
    "for k, v in exceptional_samples.items():\n",
    "    v = v.replace('png', 'jpg')\n",
    "    image_path = os.path.join(image_root_dir, v)\n",
    "    image = Image.open(image_path)\n",
    "    print(k)\n",
    "    # specify height and width of figure in pixels\n",
    "    # plt.figure(figsize=(2,2))\n",
    "    # plt.imshow(image)\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 511/11931 [00:00<00:04, 2560.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11931/11931 [00:04<00:00, 2391.55it/s]\n",
      "100%|██████████| 109816/109816 [00:46<00:00, 2338.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "해당없음 107026\n",
      "묶음머리 6673\n",
      "넘긴머리 5351\n",
      "악성곱슬머리 656\n",
      "땋은머리 960\n",
      "기타악세사리 758\n",
      "군인머리(반삭) 227\n",
      "기타 96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "suspected_samples = {\n",
    "    '해당없음': [],\n",
    "    '묶음머리': [],\n",
    "    '넘긴머리': [],\n",
    "    '악성곱슬머리': [],\n",
    "    '땋은머리': [],\n",
    "    '기타악세사리': [],\n",
    "    '군인머리(반삭)': [],\n",
    "    '기타': []\n",
    "}\n",
    "for k, v in tqdm.tqdm(khs_val_paths.items()):\n",
    "    abs_path = os.path.join(label_root_dir, v)\n",
    "    with open(abs_path, 'r') as f:\n",
    "        label = json.load(f)\n",
    "        exceptional = label['exceptional']\n",
    "        if exceptional in suspected_samples.keys():\n",
    "            suspected_samples[exceptional].append(k)\n",
    "for k, v in tqdm.tqdm(khs_train_paths.items()):\n",
    "    abs_path = os.path.join(label_root_dir, v)\n",
    "    with open(abs_path, 'r') as f:\n",
    "        label = json.load(f)\n",
    "        exceptional = label['exceptional']\n",
    "        if exceptional in suspected_samples.keys():\n",
    "            suspected_samples[exceptional].append(k)\n",
    "for k, v in suspected_samples.items():\n",
    "    print(k, len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Author: tianhao 120090472@link.cuhk.edu.cn\n",
    "Date: 2023-11-12 16:12:08\n",
    "LastEditors: tianhao 120090472@link.cuhk.edu.cn\n",
    "LastEditTime: 2023-11-14 13:59:04\n",
    "FilePath: /DatProc/X10.get_ours_and_khs.ipynb\n",
    "Description: \n",
    "\n",
    "Copyright (c) 2023 by ${git_name_email}, All Rights Reserved. \n",
    "'''\n",
    "for k in suspected_samples.keys():\n",
    "    if k != '해당없음': continue\n",
    "    print(f'Samples of {k}')\n",
    "    num_vis = 10\n",
    "    for _v in suspected_samples[k][::40]:\n",
    "        image_path = os.path.join(image_root_dir, _v.replace('png', 'jpg'))\n",
    "        print(image_path)\n",
    "        image = Image.open(image_path)\n",
    "        plt.figure(figsize=(2,2))\n",
    "        plt.imshow(image)\n",
    "        plt.show()\n",
    "        num_vis -= 1\n",
    "        if num_vis == 0: break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataset.json\n",
    "import json, os, tqdm\n",
    "\n",
    "delete_items = []\n",
    "label_root_dir = '/data3/khs_labels/'\n",
    "dataset_json_path = '/data2/chence/PanoHeadData/single_view_hq/dataset.json'\n",
    "suspected_samples = ['기타악세사리', '땋은머리']\n",
    "\n",
    "print(f'Loading present dataset meta from: {dataset_json_path}')\n",
    "with open(dataset_json_path, 'r') as f:\n",
    "    dataset = json.load(f)\n",
    "\n",
    "# get datasource\n",
    "print(f'Filtering KHS data...')\n",
    "pbar = tqdm.tqdm(dataset.items())\n",
    "for image_name, image_meta in pbar:\n",
    "    source = image_meta['data_source']\n",
    "    if not(source.startswith('K-Hairstyle')): continue\n",
    "    path_label = 'validation_labels' if source == 'K-Hairstyle/Validation' else 'training_labels'\n",
    "    new_path = image_meta['align_image_path'].replace('align_images', path_label)\n",
    "    new_path = new_path.replace('._00.png', '.json') if new_path.endswith('._00.png') else new_path.replace('_00.png', '.json')\n",
    "    new_path = new_path.replace('-', '_')\n",
    "    abs_path = os.path.join(label_root_dir, new_path)\n",
    "    pbar.set_description(f'Processing {new_path}')\n",
    "    with open(abs_path, 'r') as f:\n",
    "        label = json.load(f)\n",
    "        exceptional = label['exceptional']\n",
    "        if exceptional in suspected_samples:\n",
    "            delete_items.append(image_name)\n",
    "\n",
    "print(f'In total: {len(delete_items)} items to be deleted.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading present dataset meta from: /data2/chence/PanoHeadData/multi_view_hq/dataset.json...Done.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Author: tianhao 120090472@link.cuhk.edu.cn\n",
    "Date: 2023-11-14 00:15:44\n",
    "LastEditors: tianhao 120090472@link.cuhk.edu.cn\n",
    "LastEditTime: 2023-11-14 01:10:58\n",
    "FilePath: /DatProc/X10.remove_unwanted_khs.py\n",
    "Description: \n",
    "\n",
    "Copyright (c) 2023 by ${git_name_email}, All Rights Reserved. \n",
    "'''\n",
    "# read dataset.json\n",
    "import json, os, tqdm\n",
    "\n",
    "ours_delete = []\n",
    "khs_delete = []\n",
    "label_root_dir = '/data3/khs_labels/'\n",
    "dataset_json_path = '/data2/chence/PanoHeadData/multi_view_hq/dataset.json'\n",
    "suspected_samples = ['기타악세사리', '땋은머리']\n",
    "samples = [(1224, 7), (3102, 0), (3929, 0), (4033, 0), (4032,3), (4288, 2), (4289, 0), (4473, 0)]\n",
    "\n",
    "print(f'Loading present dataset meta from: {dataset_json_path}', end='...', flush=True)\n",
    "with open(dataset_json_path, 'r') as f:\n",
    "    dataset = json.load(f)\n",
    "print(f'Done.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get datasource\n",
    "print(f'Filtering KHS data...')\n",
    "pbar = tqdm.tqdm(samples)\n",
    "for model_id, image_id in pbar:\n",
    "    key = f'{model_id:05d}/img{image_id:08d}.png'\n",
    "    assert key in dataset.keys()\n",
    "    source = dataset[key]['data_source']\n",
    "    path_label = 'validation_labels' if source == 'K-Hairstyle/Validation' else 'training_labels'\n",
    "    new_path = dataset[key]['align_image_path'].replace('align_images', path_label)\n",
    "    new_path = new_path.replace('._00.png', '.json') if new_path.endswith('._00.png') else new_path.replace('_00.png', '.json')\n",
    "    new_path = new_path.replace('-', '_')\n",
    "    abs_path = os.path.join(label_root_dir, new_path)\n",
    "    pbar.set_description(f'Processing {new_path}')\n",
    "    with open(abs_path, 'r') as f:\n",
    "        label = json.load(f)\n",
    "        style = label['basestyle']\n",
    "        exceptional = label['exceptional']\n",
    "        print(f'{key}:\\n\\tStyle:{style}\\n\\tExceptional:{exceptional}')\n",
    "    pbar.update()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184\n"
     ]
    }
   ],
   "source": [
    "headings = 4\n",
    "model_ids = set()\n",
    "with open('./temp2.txt','r') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines[headings:]:\n",
    "        model_id = os.path.basename(os.path.dirname(line))\n",
    "        model_ids.add(model_id) \n",
    "print(len(model_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sides = set()\n",
    "# side_samples= {}\n",
    "# hairstyles = set()\n",
    "# exceptionals = set()\n",
    "# hairstyle_samples = {}\n",
    "# exceptional_samples = {}\n",
    "# for k, v in tqdm.tqdm(khs_val_paths.items()):\n",
    "#     abs_path = os.path.join(label_root_dir, v)\n",
    "#     with open(abs_path, 'r') as f:\n",
    "#         label = json.load(f)\n",
    "#         exceptional = label['exceptional']\n",
    "#         if not(exceptional == '해당없음'): continue\n",
    "#         hairstyle = label['basestyle']\n",
    "#         hairstyles.add(hairstyle)\n",
    "#         if hairstyle not in hairstyle_samples:\n",
    "#             hairstyle_samples[hairstyle] = [k]\n",
    "#         else:\n",
    "#             hairstyle_samples[hairstyle].append(k)\n",
    "# for k, v in tqdm.tqdm(khs_train_paths.items()):\n",
    "#     abs_path = os.path.join(label_root_dir, v)\n",
    "#     with open(abs_path, 'r') as f:\n",
    "#         label = json.load(f)\n",
    "#         exceptional = label['exceptional']\n",
    "#         if not(exceptional == '해당없음'): continue\n",
    "#         hairstyle = label['basestyle']\n",
    "#         hairstyles.add(hairstyle)\n",
    "#         if hairstyle not in hairstyle_samples:\n",
    "#             hairstyle_samples[hairstyle] = [k]\n",
    "#         else:\n",
    "#             hairstyle_samples[hairstyle].append(k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datproc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
