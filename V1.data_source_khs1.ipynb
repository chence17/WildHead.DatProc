{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_root /data_new/chence/K-Hairstyle-Filtered/Training/rawset\n",
      "data_source K-Hairstyle/Training\n"
     ]
    }
   ],
   "source": [
    "data_root = '/data_new/chence/K-Hairstyle-Filtered/Training/rawset'\n",
    "data_source = 'K-Hairstyle/Training'\n",
    "print('data_root', data_root)\n",
    "print('data_source', data_source)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "align_images_dir = os.path.join(data_root, 'align_images')\n",
    "align_parsing_dir = os.path.join(data_root, 'align_parsing')\n",
    "head_images_dir = os.path.join(data_root, 'head_images')\n",
    "head_parsing_dir = os.path.join(data_root, 'head_parsing')\n",
    "assert os.path.exists(align_images_dir)\n",
    "assert os.path.exists(align_parsing_dir)\n",
    "assert os.path.exists(head_images_dir)\n",
    "assert os.path.exists(head_parsing_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cam_coords(c2w):\n",
    "    # World Coordinate System: x(right), y(up), z(forward)\n",
    "    T = c2w[:3, 3]\n",
    "    x, y, z = T\n",
    "    r = np.sqrt(x**2+y**2+z**2)\n",
    "    # theta = np.rad2deg(np.arctan(np.sqrt(x**2+z**2)/y))\n",
    "    theta = np.rad2deg(np.arctan2(x, z))\n",
    "    if theta >= -90 and theta <= 90:\n",
    "        theta += 90\n",
    "    elif theta>=-180 and theta < -90:\n",
    "        theta += 90\n",
    "    elif theta>90 and theta <= 180:\n",
    "        theta -= 270\n",
    "    else:\n",
    "        raise ValueError('theta out of range')\n",
    "    # phi = np.rad2deg(np.arctan(z/x))+180\n",
    "    phi = np.rad2deg(np.arccos(y/r))\n",
    "    return [theta, phi, r, x, y, z] # [:3] sperical cood, [3:] cartesian cood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_root, 'meta_filtered.json'), 'r') as f:\n",
    "    cur_meta_data = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'k-hairstyle'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_meta_data['images/0003.rawset/0001.가르마/0126.CP032677/CP032677-016.jpg']['data_source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109816/109816 [00:02<00:00, 51485.87it/s]\n",
      "  0%|          | 0/109816 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/109816 [00:02<62:27:53,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "back\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/109816 [00:02<23:36:27,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109816/109816 [00:03<00:00, 31229.85it/s]\n"
     ]
    }
   ],
   "source": [
    "# meta_idx = 1\n",
    "\n",
    "# print('meta_idx', meta_files[meta_idx])\n",
    "# with open(os.path.join(data_root, meta_files[meta_idx]), 'r') as f:\n",
    "#     cur_meta_data = json.load(f)\n",
    "\n",
    "\n",
    "vis = True\n",
    "\n",
    "import tqdm\n",
    "import time\n",
    "\n",
    "for k in tqdm.tqdm(cur_meta_data.keys()):\n",
    "    # print(k, cur_meta_data[k]['data_source'])\n",
    "    if cur_meta_data[k]['data_source'] != data_source:\n",
    "        cur_meta_data[k]['data_source'] = data_source\n",
    "    for hk in cur_meta_data[k]['head'].keys():\n",
    "        if cur_meta_data[k]['head'][hk]['camera'] is None:\n",
    "            print('camera is None')\n",
    "            del cur_meta_data[k]['head'][hk]\n",
    "            continue\n",
    "        cur_cam = cur_meta_data[k]['head'][hk]['camera']\n",
    "        cur_TMatrix = np.array(cur_cam[:16]).reshape(4, 4)\n",
    "        cur_cam_scoord = get_cam_coords(cur_TMatrix)\n",
    "        cur_meta_data[k]['head'][hk][\"camera_scoord\"] = cur_cam_scoord\n",
    "        # front [45, 135]\n",
    "        # right [-45, 45]\n",
    "        # back [-135, -45]\n",
    "        # left [-180, -135], [135, 180]\n",
    "        theta = cur_cam_scoord[0]\n",
    "        if theta >= -45 and theta <= 45:\n",
    "            cur_meta_data[k]['head'][hk]['view'] = 'right'\n",
    "        elif theta >= 45 and theta <= 135:\n",
    "            cur_meta_data[k]['head'][hk]['view'] = 'front'\n",
    "        elif theta >= -135 and theta <= -45:\n",
    "            cur_meta_data[k]['head'][hk]['view'] = 'back'\n",
    "        else:\n",
    "            cur_meta_data[k]['head'][hk]['view'] = 'left'\n",
    "    if cur_meta_data[k]['head'] == {}:\n",
    "        print('head is None')\n",
    "        del cur_meta_data[k]\n",
    "        continue\n",
    "\n",
    "front_flag = False\n",
    "right_flag = False\n",
    "back_flag = False\n",
    "left_flag = False\n",
    "\n",
    "import cv2\n",
    "from utils.tool import render_camera\n",
    "\n",
    "def show_render_check(cur_dt, data_root):\n",
    "    cam = np.array(cur_dt['camera'])\n",
    "    r_img = render_camera(cam)\n",
    "    h, w = r_img.shape[:2]\n",
    "    a_img = cv2.imread(os.path.join(data_root, cur_dt['align_image_path']))\n",
    "    a_img = cv2.cvtColor(a_img, cv2.COLOR_BGR2RGB)\n",
    "    a_img = cv2.resize(a_img, (h, w))\n",
    "    vis_img = np.hstack([r_img, a_img])\n",
    "    # display(Image.fromarray(vis_img))\n",
    "    cv2.imwrite(f'{time.time()}render_check.jpg', vis_img[..., ::-1])\n",
    "\n",
    "for k in tqdm.tqdm(cur_meta_data.keys()):\n",
    "    assert cur_meta_data[k]['data_source'] == data_source\n",
    "    for hk in cur_meta_data[k]['head'].keys():\n",
    "        assert cur_meta_data[k]['head'][hk]['camera'] is not None\n",
    "        cur_dt = cur_meta_data[k]['head'][hk]\n",
    "        if not front_flag:\n",
    "            if cur_dt['view'] == 'front':\n",
    "                print(cur_dt['view'])\n",
    "                show_render_check(cur_dt, data_root)\n",
    "                front_flag = True\n",
    "        if not right_flag:\n",
    "            if cur_dt['view'] == 'right':\n",
    "                print(cur_dt['view'])\n",
    "                show_render_check(cur_dt, data_root)\n",
    "                right_flag = True\n",
    "        if not back_flag:\n",
    "            if cur_dt['view'] == 'back':\n",
    "                print(cur_dt['view'])\n",
    "                show_render_check(cur_dt, data_root)\n",
    "                back_flag = True\n",
    "        if not left_flag:\n",
    "            if cur_dt['view'] == 'left':\n",
    "                print(cur_dt['view'])\n",
    "                show_render_check(cur_dt, data_root)\n",
    "                left_flag = True\n",
    "\n",
    "# with open(os.path.join(data_root, meta_files[meta_idx]), 'w') as f:\n",
    "#     json.dump(cur_meta_data, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_dir = '/data_new/chence/ExportedSVhq'\n",
    "os.makedirs(export_dir, exist_ok=True)\n",
    "\n",
    "export_align_images_dir = os.path.join(export_dir, 'align_images')\n",
    "export_align_parsing_dir = os.path.join(export_dir, 'align_parsing')\n",
    "export_head_images_dir = os.path.join(export_dir, 'head_images')\n",
    "export_head_parsing_dir = os.path.join(export_dir, 'head_parsing')\n",
    "os.makedirs(export_align_images_dir, exist_ok=True)\n",
    "os.makedirs(export_align_parsing_dir, exist_ok=True)\n",
    "os.makedirs(export_head_images_dir, exist_ok=True)\n",
    "os.makedirs(export_head_parsing_dir, exist_ok=True)\n",
    "\n",
    "export_start_idx = 0+68766+25754+15459+25780+11931\n",
    "export_meta_json = os.path.join(export_dir, f'meta_{export_start_idx:07d}.json')\n",
    "export_meta_dict = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data_new/chence/ExportedSVhq/meta_0147690.json'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export_meta_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109816/109816 [00:00<00:00, 159441.63it/s]\n"
     ]
    }
   ],
   "source": [
    "for k in tqdm.tqdm(cur_meta_data.keys()):\n",
    "    for hk in cur_meta_data[k]['head'].keys():\n",
    "        export_folder = str(export_start_idx // 1000).zfill(5)\n",
    "        export_name = 'img'+str(export_start_idx).zfill(8)+'.png'\n",
    "        export_key = f'{export_folder}/{export_name}'\n",
    "        export_meta_dict[export_key] = {'data_source': data_source}\n",
    "        export_meta_dict[export_key].update(cur_meta_data[k]['head'][hk])\n",
    "        export_start_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109816\n"
     ]
    }
   ],
   "source": [
    "with open(export_meta_json, 'w') as f:\n",
    "    json.dump(export_meta_dict, f, indent=4)\n",
    "print(len(export_meta_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "export_start_idx 257506\n"
     ]
    }
   ],
   "source": [
    "print('export_start_idx', export_start_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def work(export_key, data_item, data_root, export_align_images_dir, export_align_parsing_dir, export_head_images_dir, export_head_parsing_dir):\n",
    "    try:\n",
    "        export_folder = export_key.split('/')[0]\n",
    "        export_align_image_folder = os.path.join(export_align_images_dir, export_folder)\n",
    "        export_align_parsing_folder = os.path.join(export_align_parsing_dir, export_folder)\n",
    "        export_head_image_folder = os.path.join(export_head_images_dir, export_folder)\n",
    "        export_head_parsing_folder = os.path.join(export_head_parsing_dir, export_folder)\n",
    "        os.makedirs(export_align_image_folder, exist_ok=True)\n",
    "        os.makedirs(export_align_parsing_folder, exist_ok=True)\n",
    "        os.makedirs(export_head_image_folder, exist_ok=True)\n",
    "        os.makedirs(export_head_parsing_folder, exist_ok=True)\n",
    "\n",
    "        export_align_image_path = os.path.join(export_align_images_dir, export_key)\n",
    "        export_align_parsing_path = os.path.join(export_align_parsing_dir, export_key)\n",
    "        export_head_image_path = os.path.join(export_head_images_dir, export_key)\n",
    "        export_head_parsing_path = os.path.join(export_head_parsing_dir, export_key)\n",
    "\n",
    "        cur_align_image_path = os.path.join(data_root, data_item['align_image_path'])\n",
    "        assert os.path.exists(cur_align_image_path)\n",
    "        if cur_align_image_path.endswith('.png') or cur_align_image_path.endswith('.PNG'):\n",
    "            os.system(f'cp {cur_align_image_path} {export_align_image_path}')\n",
    "        else:\n",
    "            cur_align_image_data = cv2.imread(cur_align_image_path)\n",
    "            cv2.imwrite(export_align_image_path, cur_align_image_data)\n",
    "\n",
    "        cur_align_parsing_path = os.path.join(data_root, data_item['align_parsing_path'])\n",
    "        assert os.path.exists(cur_align_parsing_path)\n",
    "        assert cur_align_parsing_path.endswith('.png') or cur_align_parsing_path.endswith('.PNG')\n",
    "        os.system(f'cp {cur_align_parsing_path} {export_align_parsing_path}')\n",
    "\n",
    "        cur_head_image_path = os.path.join(data_root, data_item['head_image_path'])\n",
    "        assert os.path.exists(cur_head_image_path)\n",
    "        if cur_head_image_path.endswith('.png') or cur_head_image_path.endswith('.PNG'):\n",
    "            os.system(f'cp {cur_head_image_path} {export_head_image_path}')\n",
    "        else:\n",
    "            cur_head_image_data = cv2.imread(cur_head_image_path)\n",
    "            cv2.imwrite(export_head_image_path, cur_head_image_data)\n",
    "\n",
    "        cur_head_parsing_path = os.path.join(data_root, data_item['head_parsing_path'])\n",
    "        assert os.path.exists(cur_head_parsing_path)\n",
    "        assert cur_head_parsing_path.endswith('.png') or cur_head_parsing_path.endswith('.PNG')\n",
    "        os.system(f'cp {cur_head_parsing_path} {export_head_parsing_path}')\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109816/109816 [7:39:46<00:00,  3.98it/s]  \n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "import cv2\n",
    "\n",
    "global progress_bar\n",
    "progress_bar = tqdm.tqdm(total=len(export_meta_dict))\n",
    "\n",
    "def update_progress_bar(_):\n",
    "    progress_bar.update()\n",
    "\n",
    "pool = mp.Pool(processes=64)\n",
    "for k, v in export_meta_dict.items():\n",
    "    pool.apply_async(work, (\n",
    "        k,\n",
    "        v,\n",
    "        data_root,\n",
    "        export_align_images_dir,\n",
    "        export_align_parsing_dir,\n",
    "        export_head_images_dir,\n",
    "        export_head_parsing_dir,\n",
    "    ), callback=update_progress_bar)\n",
    "pool.close()\n",
    "pool.join()\n",
    "progress_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load instance dict.\n"
     ]
    }
   ],
   "source": [
    "import os.path as osp\n",
    "\n",
    "export_dir = '/data_new/chence/ExportedMVhq'\n",
    "os.makedirs(export_dir, exist_ok=True)\n",
    "\n",
    "export_align_images_dir = os.path.join(export_dir, 'align_images')\n",
    "export_align_parsing_dir = os.path.join(export_dir, 'align_parsing')\n",
    "export_head_images_dir = os.path.join(export_dir, 'head_images')\n",
    "export_head_parsing_dir = os.path.join(export_dir, 'head_parsing')\n",
    "os.makedirs(export_align_images_dir, exist_ok=True)\n",
    "os.makedirs(export_align_parsing_dir, exist_ok=True)\n",
    "os.makedirs(export_head_images_dir, exist_ok=True)\n",
    "os.makedirs(export_head_parsing_dir, exist_ok=True)\n",
    "\n",
    "export_start_idx = 0+11931\n",
    "export_meta_json = os.path.join(export_dir, f'meta_{export_start_idx:07d}.json')\n",
    "export_meta_dict = {}\n",
    "export_instance_json = os.path.join(export_dir, 'instance.json')\n",
    "if osp.exists(export_instance_json):\n",
    "    print(\"load instance dict.\")\n",
    "    with open(export_instance_json, 'r') as f:\n",
    "        export_instance_dict = json.load(f)\n",
    "else:\n",
    "    export_instance_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data_new/chence/ExportedMVhq/meta_0011931.json'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export_meta_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109816/109816 [00:00<00:00, 190561.37it/s]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "instance_keys = []\n",
    "for k in tqdm.tqdm(cur_meta_data.keys()):\n",
    "    image_name = osp.basename(k)\n",
    "    image_dir = osp.dirname(k)\n",
    "    dtsrc = cur_meta_data[k]['data_source']\n",
    "    instance_key = f'{dtsrc}/{image_dir}'\n",
    "    instance_keys.append(instance_key)\n",
    "\n",
    "instance_idx = len(export_instance_dict)\n",
    "instance_keys = sorted(list(set(instance_keys)))\n",
    "for instance_key in instance_keys:\n",
    "    if instance_key not in export_instance_dict.items():\n",
    "        export_instance_dict[instance_key] = str(instance_idx).zfill(5)\n",
    "        instance_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/109816 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109816/109816 [00:02<00:00, 47728.44it/s]\n"
     ]
    }
   ],
   "source": [
    "instance_image_idx = {}\n",
    "for k in tqdm.tqdm(cur_meta_data.keys()):\n",
    "    for hk in cur_meta_data[k]['head'].keys():\n",
    "        image_name = osp.basename(k)\n",
    "        image_dir = osp.dirname(k)\n",
    "        dtsrc = cur_meta_data[k]['data_source']\n",
    "        instance_key = f'{dtsrc}/{image_dir}'\n",
    "        export_folder = export_instance_dict[instance_key]\n",
    "        if export_folder not in instance_image_idx.keys():\n",
    "            instance_image_idx[export_folder] = 0\n",
    "        export_name = 'img'+str(instance_image_idx[export_folder]).zfill(8)+'.png'\n",
    "        instance_image_idx[export_folder] += 1\n",
    "        export_key = f'{export_folder}/{export_name}'\n",
    "        export_meta_dict[export_key] = {'data_source': data_source}\n",
    "        export_meta_dict[export_key].update(cur_meta_data[k]['head'][hk])\n",
    "        export_start_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121747"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export_start_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(export_meta_json, 'w') as f:\n",
    "    json.dump(export_meta_dict, f, indent=4)\n",
    "\n",
    "with open(export_instance_json, 'w') as f:\n",
    "    json.dump(export_instance_dict, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109816\n"
     ]
    }
   ],
   "source": [
    "print(len(export_meta_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109816/109816 [1:12:57<00:00, 25.08it/s]\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "import cv2\n",
    "\n",
    "global progress_bar\n",
    "progress_bar = tqdm.tqdm(total=len(export_meta_dict))\n",
    "\n",
    "def update_progress_bar(_):\n",
    "    progress_bar.update()\n",
    "\n",
    "pool = mp.Pool(processes=64)\n",
    "for k, v in export_meta_dict.items():\n",
    "    pool.apply_async(work, (\n",
    "        k,\n",
    "        v,\n",
    "        data_root,\n",
    "        export_align_images_dir,\n",
    "        export_align_parsing_dir,\n",
    "        export_head_images_dir,\n",
    "        export_head_parsing_dir,\n",
    "    ), callback=update_progress_bar)\n",
    "pool.close()\n",
    "pool.join()\n",
    "progress_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "export_start_idx 121747\n"
     ]
    }
   ],
   "source": [
    "print('export_start_idx', export_start_idx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datproc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
