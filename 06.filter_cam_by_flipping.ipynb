{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os, tqdm\n",
    "import numpy as np\n",
    "from dpestimator import HeadPoseEstimator\n",
    "from IPython.display import display\n",
    "import PIL.Image as Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from visualize.vis_3d import render_camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '/data2/chence/PanoHeadData/single_view_hq/dataset_v2_balanced_nohat.json'\n",
    "pe_info_path = '/data2/chence/PanoHeadData/single_view_hq/align_images/pose_estimation_info.json'\n",
    "with open(dataset_path, 'r') as f:\n",
    "    dataset_json = json.load(f)\n",
    "image_names = list(dataset_json.keys())\n",
    "pe = HeadPoseEstimator(weights_file = 'assets/whenet_1x3x224x224_prepost.onnx')\n",
    "pose_estimation_info = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"data_source\": \"FFHQ\",\n",
      "    \"camera\": [\n",
      "        0.9199845194816589,\n",
      "        -0.004887542687356472,\n",
      "        0.391928493976593,\n",
      "        -1.0582069158554077,\n",
      "        0.02866552025079727,\n",
      "        -0.9964868426322937,\n",
      "        -0.07882832735776901,\n",
      "        0.21283648908138275,\n",
      "        0.3909051716327667,\n",
      "        0.08360766619443893,\n",
      "        -0.9166123270988464,\n",
      "        2.474853277206421,\n",
      "        0.0,\n",
      "        0.0,\n",
      "        0.0,\n",
      "        1.0,\n",
      "        4.2647,\n",
      "        0.0,\n",
      "        0.5,\n",
      "        0.0,\n",
      "        4.2647,\n",
      "        0.5,\n",
      "        0.0,\n",
      "        0.0,\n",
      "        1.0\n",
      "    ],\n",
      "    \"hpose\": [\n",
      "        -23.012277603149414,\n",
      "        1.7729947566986084,\n",
      "        -5.218562602996826\n",
      "    ],\n",
      "    \"align_box\": [\n",
      "        139.2390243902439,\n",
      "        139.55121951219513,\n",
      "        738.0292682926829,\n",
      "        738.0292682926829\n",
      "    ],\n",
      "    \"align_quad\": [\n",
      "        [\n",
      "            139.4185975609756,\n",
      "            139.7737471417683\n",
      "        ],\n",
      "        [\n",
      "            139.4185975609756,\n",
      "            877.7139481707317\n",
      "        ],\n",
      "        [\n",
      "            877.3588414634146,\n",
      "            877.7138719512195\n",
      "        ],\n",
      "        [\n",
      "            877.3588414634146,\n",
      "            139.77373285060975\n",
      "        ]\n",
      "    ],\n",
      "    \"view\": \"front\",\n",
      "    \"head_image_path\": \"head_images/30838_00.png\",\n",
      "    \"head_parsing_path\": \"head_parsing/30838_00.png\",\n",
      "    \"align_image_path\": \"align_images/30838_00.png\",\n",
      "    \"align_parsing_path\": \"align_parsing/30838_00.png\",\n",
      "    \"camera_scoord\": [\n",
      "        66.84923774085792,\n",
      "        85.47877874577978,\n",
      "        2.699999998434827,\n",
      "        -1.0582069158554077,\n",
      "        0.21283648908138275,\n",
      "        2.474853277206421\n",
      "    ],\n",
      "    \"svd_score\": 0.4996859456678176,\n",
      "    \"laplacian_score\": 475.57311619805154,\n",
      "    \"iv2b_ratio\": 0.08323170731707319,\n",
      "    \"head_region_thresh\": 0.7599859923210156,\n",
      "    \"dup_num\": 2\n",
      "}\n",
      "00000/img00000000.png\n"
     ]
    }
   ],
   "source": [
    "for image_name in image_names[:10]:\n",
    "    print(json.dumps(dataset_json[image_name], indent = 4))\n",
    "    print(image_name)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00000/img00000000.jpg\n",
      "{\n",
      "    \"yaw\": -22.181884765625,\n",
      "    \"yaw_bar\": 21.44854736328125,\n",
      "    \"pitch\": -6.54083251953125,\n",
      "    \"pitch_bar\": -3.848846435546875,\n",
      "    \"roll\": 2.8795013427734375,\n",
      "    \"roll_bar\": -3.1965866088867188\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "saved_json_path = '/data2/chence/PanoHeadData/single_view_hq/pose_estimation_info.json'\n",
    "with open(saved_json_path, 'r') as f:\n",
    "    saved_json_meta = json.load(f)\n",
    "\n",
    "for image_name, image_meta in saved_json_meta.items():\n",
    "    print(image_name)\n",
    "    print(json.dumps(image_meta, indent=4))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 404524/404524 [00:04<00:00, 91988.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "front 160140\n",
      "back 49636\n",
      "left 32397\n",
      "right 37464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vis_num = 5\n",
    "losses = []\n",
    "vised = 0\n",
    "thresh = 10\n",
    "\n",
    "failed = {'front':[], 'back':[], 'left':[], 'right':[]}\n",
    "success = {'front':[], 'back':[], 'left':[], 'right':[]}\n",
    "for image_name, image_meta in tqdm.tqdm(dataset_json.items()):\n",
    "    view = dataset_json[image_name]['view']\n",
    "    # if view != 'back': continue\n",
    "    campose = dataset_json[image_name]['camera']\n",
    "    image_name = image_name.replace('.png', '.jpg')\n",
    "    \n",
    "    # image_path = os.path.join('/data2/chence/PanoHeadData/single_view_hq/align_images', image_name)\n",
    "    # image_data = cv2.imread(image_path)\n",
    "    # image_data_flipped = cv2.flip(image_data, 1)\n",
    "    # image_data_rgb = cv2.cvtColor(image_data, cv2.COLOR_BGR2RGB)\n",
    "    # image_data_flipped_rgb = cv2.cvtColor(image_data_flipped, cv2.COLOR_BGR2RGB)\n",
    "    # camera_vis = render_camera(np.array(campose))\n",
    "\n",
    "    yaw, roll, pitch = saved_json_meta[image_name]['yaw'], saved_json_meta[image_name]['roll'], saved_json_meta[image_name]['pitch']\n",
    "    yaw_bar, roll_bar, pitch_bar = saved_json_meta[image_name]['yaw_bar'], saved_json_meta[image_name]['roll_bar'], saved_json_meta[image_name]['pitch_bar']\n",
    "    yaw_bar = -yaw_bar if yaw_bar * yaw > 0 else yaw_bar\n",
    "    roll_bar = -roll_bar if roll_bar * roll > 0 else roll_bar\n",
    "    pitch_bar = -pitch_bar if pitch_bar * pitch < 0 else pitch_bar\n",
    "\n",
    "    yaw_loss = np.sqrt((yaw + yaw_bar)**2)\n",
    "    roll_loss = np.sqrt((roll + roll_bar)**2)\n",
    "    pitch_loss = np.sqrt((pitch - pitch_bar)**2)\n",
    "    loss = np.sqrt(\n",
    "        (1  *(pitch - pitch_bar))**2 + \n",
    "        (1  *(roll + roll_bar))**2 + \n",
    "        (1  *(yaw + yaw_bar))**2\n",
    "    )\n",
    "    if loss < thresh: \n",
    "        losses.append(loss)\n",
    "        success[view].append((image_name, campose, loss))\n",
    "    else: \n",
    "\n",
    "        # fig, ax = plt.subplots(1, 3, figsize = (12, 4))\n",
    "        # ax[0].imshow(image_data_rgb)\n",
    "        # ax[1].imshow(camera_vis)\n",
    "        # ax[2].imshow(image_data_flipped_rgb)\n",
    "        # fig.suptitle(f'{image_name}, loss: {loss:.2f}')\n",
    "        # display(fig)\n",
    "        \n",
    "        failed[view].append((image_name, campose, loss))\n",
    "    #     vis_num += 1\n",
    "    # if vis_num == vised: break\n",
    "for key, value in success.items():\n",
    "    print(key, len(value))\n",
    "# for key, value in failed.items():\n",
    "#     print(key, len(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279637\n"
     ]
    }
   ],
   "source": [
    "vis_num = 10\n",
    "filtered_cam_dict = {}\n",
    "for _view in ['front', 'back', 'left', 'right']:\n",
    "    for image_name, campose, loss in success[_view]:\n",
    "        filtered_cam_dict[image_name] = dataset_json[image_name.replace('.jpg', '.png')]\n",
    "print(len(filtered_cam_dict))\n",
    "with open('/data2/chence/PanoHeadData/single_view_hq/dataset-cam-filtered.json', 'w') as f:\n",
    "    json.dump(filtered_cam_dict, f, indent = 4)\n",
    "    # image_path = os.path.join('/data2/chence/PanoHeadData/single_view_hq/align_images', image_name)\n",
    "    # image_data = cv2.imread(image_path)\n",
    "    # image_data_flipped = cv2.flip(image_data, 1)\n",
    "    # image_data_rgb = cv2.cvtColor(image_data, cv2.COLOR_BGR2RGB)\n",
    "    # image_data_flipped_rgb = cv2.cvtColor(image_data_flipped, cv2.COLOR_BGR2RGB)\n",
    "    # camera_vis = render_camera(np.array(campose))\n",
    "    # fig, ax = plt.subplots(1, 3, figsize = (12, 4))\n",
    "    # ax[0].imshow(image_data_rgb)\n",
    "    # ax[1].imshow(camera_vis)\n",
    "    # ax[2].imshow(image_data_flipped_rgb)\n",
    "    # fig.suptitle(f'{image_name}, loss: {loss:.2f}')\n",
    "    # display(fig)\n",
    "    # vis_num -= 1\n",
    "    # if vis_num == 0:break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datproc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
